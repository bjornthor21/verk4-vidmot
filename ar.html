
<html lang='en'>
<head>
    <meta charset='UTF-8'>
    <title>Mediapipe Hand Gesture Recognizer</title>

    <!-- <script type="importmap">
      {
        "imports": {
          "three": "https://unpkg.com/three@v0.158.0/build/three.module.js"
        }
      }
    </script> -->
    <script src="https://unpkg.com/three@0.126.0/examples/js/loaders/GLTFLoader.js"></script>
</head>
<body>
    <div>
      <button id='webcamButton'>ENABLE WEBCAM</button>
      <div>
          <video id='webcam' autoplay></video>
          <canvas id="threeCanvas" style="position: absolute; top: 0; left: 0; transform: scaleX(-1);"></canvas>
          <canvas id='output_canvas' style="position: absolute; left: 0px; top: 0px; transform: scaleX(-1)" width='480' height='360'></canvas>
          <h1 id='gesture_output'></h1>
          <h2>X <span id='x_output'></span></h2>
          <h2>Y <span id='y_output'></span></h2>
      </div>
  </div>
  <button onclick="activateXR()">Activate AR</button>
    <script type="module">
        import { GestureRecognizer, FilesetResolver, DrawingUtils } from 'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3';
        import * as THREE from 'https://unpkg.com/three@v0.158.0/build/three.module.js';


        let gestureRecognizer;
        let runningMode = 'IMAGE';
        let enableWebcamButton;
        let webcamRunning = false;
        const videoWidth = '380px';
        const videoHeight = '292px';

        const createGestureRecognizer = async () => {
         
            const vision = await FilesetResolver.forVisionTasks('https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm');
            gestureRecognizer = await GestureRecognizer.createFromOptions(vision, {
                baseOptions: {
                    modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task',
                    delegate: 'GPU'
                },
                runningMode: runningMode,
            });
        };
        createGestureRecognizer();

        const video = document.getElementById('webcam');
        const canvasElement = document.getElementById('output_canvas');
        const canvasCtx = canvasElement.getContext('2d');
        const gestureOutput = document.getElementById('gesture_output');
        const xOutput = document.getElementById('x_output');
        const yOutput = document.getElementById('y_output');

        enableWebcamButton = document.getElementById('webcamButton');
        enableWebcamButton.addEventListener('click', enableCam);

        // function enableCam(event) {
        //     if (!gestureRecognizer) {
        //         alert('Please wait for gestureRecognizer to load');
        //         return;
        //     }
        //     if (webcamRunning === true) {
        //         webcamRunning = false;
        //     }
        //     else {
        //         webcamRunning = true;
        //     }
        //     // getUsermedia parameters.
        //     const constraints = {
        //         video: true
        //     };
        //     // Activate the webcam stream.
        //     navigator.mediaDevices.getUserMedia(constraints).then(function (stream) {
        //         video.srcObject = stream;
        //         video.addEventListener('loadeddata', predictWebcam);
        //     });
        // }

        function enableCam(event) {
            if (!gestureRecognizer) {
                alert('Please wait for gestureRecognizer to load');
                return;
            }
            if (webcamRunning === true) {
                webcamRunning = false;
            }
            else {
                webcamRunning = true;
            }

            // getUsermedia parameters.
            const constraints = {
                video: {
                    // Use the rear camera if available, otherwise default to any available camera
                    facingMode: { exact: "environment" }
                }
            };

            // Activate the webcam stream.
            navigator.mediaDevices.getUserMedia(constraints).then(function (stream) {
                video.srcObject = stream;
                video.addEventListener('loadeddata', predictWebcam);
            });
        }
        let lastVideoTime = -1;
        let results = undefined;

        async function predictWebcam() {
            const webcamElement = document.getElementById('webcam');
            // Now let's start detecting the stream.
            if (runningMode === 'IMAGE') {
                runningMode = 'VIDEO';
                await gestureRecognizer.setOptions({ runningMode: 'VIDEO' });
            }

            let nowInMs = Date.now();

            if (video.currentTime !== lastVideoTime) {
                lastVideoTime = video.currentTime;
                results = gestureRecognizer.recognizeForVideo(video, nowInMs);
            }

            canvasCtx.save();
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
            const drawingUtils = new DrawingUtils(canvasCtx);
            canvasElement.style.height = videoHeight;
            webcamElement.style.height = videoHeight;
            canvasElement.style.width = videoWidth;
            webcamElement.style.width = videoWidth;

            if (results.landmarks) {
                for (const landmarks of results.landmarks) {
                    drawingUtils.drawConnectors(landmarks, GestureRecognizer.HAND_CONNECTIONS, {
                        color: '#00FF00',
                        lineWidth: 5
                    });
                    drawingUtils.drawLandmarks(landmarks, {
                        color: '#FF0000',
                        lineWidth: 2
                    });
                }
            }

            // canvasCtx.restore();
            if (results.gestures.length > 0) {
                gestureOutput.style.display = 'block';
                gestureOutput.style.width = videoWidth;
                gestureOutput.innerText = results.gestures[0][0].categoryName;
                
                parseFloat(xOutput.innerText = results.landmarks[0][0].x.toFixed(2));
                parseFloat(yOutput.innerText = results.landmarks[0][0].y.toFixed(2));
                console.log(gestureOutput.innerText)
            }
            else {
                gestureOutput.style.display = 'none';
            }

            if (webcamRunning === true) {
                window.requestAnimationFrame(predictWebcam);
            }
        }

    async function activateXR() {
    const canvas = document.createElement("canvas");
    document.body.appendChild(canvas);
    const gl = canvas.getContext("webgl", {xrCompatible: true});
  
    const scene = new THREE.Scene();

      const materials = [
      new THREE.MeshBasicMaterial({color: 0xff0000}),
      new THREE.MeshBasicMaterial({color: 0x0000ff}),
      new THREE.MeshBasicMaterial({color: 0x00ff00}),
      new THREE.MeshBasicMaterial({color: 0xff00ff}),
      new THREE.MeshBasicMaterial({color: 0x00ffff}),
      new THREE.MeshBasicMaterial({color: 0xffff00})
    ];

    const cube = new THREE.Mesh(new THREE.BoxBufferGeometry(0.2, 0.2, 0.2), materials);
    cube.position.set(1, 1, 1);
    scene.add(cube);

    const directionalLight = new THREE.DirectionalLight(0xffffff, 1);
    directionalLight.position.set(1, 1, 1);
    scene.add(directionalLight);

    const renderer = new THREE.WebGLRenderer({
      alpha: true,
      preserveDrawingBuffer: true,
      canvas: canvas,
      context: gl
    });
    renderer.autoClear = false;

    const camera = new THREE.PerspectiveCamera();
    camera.matrixAutoUpdate = false;

    const session = await navigator.xr.requestSession("immersive-ar",
      {
        requiredFeatures: ['hit-test'],
      });
    session.updateRenderState({
      baseLayer: new XRWebGLLayer(session, gl)
    });

    const referenceSpace = await session.requestReferenceSpace('local');

    const viewerSpace = await session.requestReferenceSpace('viewer');
    const hitTestSource = await session.requestHitTestSource({ space: viewerSpace });

    const loader = new THREE.GLTFLoader();

    let reticle;
    loader.load("https://immersive-web.github.io/webxr-samples/media/gltf/reticle/reticle.gltf", function(gltf) {
      reticle = gltf.scene;
      reticle.visible = false;
      scene.add(reticle);
    })

    let model;
    loader.load("https://immersive-web.github.io/webxr-samples/media/gltf/sunflower/sunflower.gltf", function(gltf) {
      model = gltf.scene;
    });

    session.addEventListener("select", (event) => {
      if (model) {
        const clone = model.clone();
        clone.position.copy(reticle.position);
        scene.add(clone);
      }
    });
    const onXRFrame = (time, frame) => {
      session.requestAnimationFrame(onXRFrame);

      gl.bindFramebuffer(gl.FRAMEBUFFER, session.renderState.baseLayer.framebuffer)

      const pose = frame.getViewerPose(referenceSpace);
      if (pose) {
        const view = pose.views[0];

        const viewport = session.renderState.baseLayer.getViewport(view);
        renderer.setSize(viewport.width, viewport.height)

        camera.matrix.fromArray(view.transform.matrix)
        camera.projectionMatrix.fromArray(view.projectionMatrix);
        camera.updateMatrixWorld(true);

        const hitTestResults = frame.getHitTestResults(hitTestSource);
        
        if (hitTestResults.length > 0 && reticle) {
          const hitPose = hitTestResults[0].getPose(referenceSpace);
          reticle.visible = true;
          reticle.position.set(hitPose.transform.position.x, hitPose.transform.position.y, hitPose.transform.position.z)
          reticle.updateMatrixWorld(true);
        }
        renderer.render(scene, camera)
      }
    }
  session.requestAnimationFrame(onXRFrame);
}
    </script>
</body>
</html>